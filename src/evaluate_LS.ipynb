{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance\n",
    "First, evaluate MCTS data on itself. Could this information be used to generate a decision threshold between BART and LS? Then, compare a few methods results:\n",
    "\n",
    "Metrics: BLEU, SARI, cos_sim\n",
    "\n",
    "Base data #1: Pseudo data\n",
    "\n",
    "Base data #2: MCTS\n",
    "\n",
    "Methods: (1) LS only\n",
    "\n",
    "(2) BART only\n",
    "\n",
    "(3) LS/BART switching\n",
    "\n",
    "(4) LS after BART\n",
    "\n",
    "(5) LS before BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 09:42:54,114 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: C:\\Users\\tempu\\.cache\\modelscope\\hub\\damo\\nlp_raner_named-entity-recognition_chinese-base-news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 09:42:56,389 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2025-02-14 09:42:56,848 - modelscope - INFO - initiate model from C:\\Users\\tempu\\.cache\\modelscope\\hub\\damo\\nlp_raner_named-entity-recognition_chinese-base-news\n",
      "2025-02-14 09:42:56,849 - modelscope - INFO - initiate model from location C:\\Users\\tempu\\.cache\\modelscope\\hub\\damo\\nlp_raner_named-entity-recognition_chinese-base-news.\n",
      "2025-02-14 09:42:56,849 - modelscope - INFO - initialize model from C:\\Users\\tempu\\.cache\\modelscope\\hub\\damo\\nlp_raner_named-entity-recognition_chinese-base-news\n",
      "2025-02-14 09:42:59,629 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "c:\\Users\\tempu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\modelscope\\utils\\checkpoint.py:550: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt_file, map_location='cpu')\n",
      "2025-02-14 09:43:00,499 - modelscope - INFO - All model checkpoint weights were used when initializing ModelForTokenClassificationWithCRF.\n",
      "\n",
      "2025-02-14 09:43:00,504 - modelscope - INFO - All the weights of ModelForTokenClassificationWithCRF were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use ModelForTokenClassificationWithCRF for predictions without further training.\n",
      "2025-02-14 09:43:00,523 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-02-14 09:43:00,524 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-02-14 09:43:00,526 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\tempu\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\nlp_raner_named-entity-recognition_chinese-base-news'}. trying to build by task and model information.\n",
      "2025-02-14 09:43:00,569 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2025-02-14 09:43:00,579 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-02-14 09:43:00,579 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-02-14 09:43:00,579 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\tempu\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\nlp_raner_named-entity-recognition_chinese-base-news', 'sequence_length': 512}. trying to build by task and model information.\n",
      "2025-02-14 09:43:00,614 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-02-14 09:43:00,614 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-02-14 09:43:00,614 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\tempu\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\nlp_raner_named-entity-recognition_chinese-base-news', 'sequence_length': 512}. trying to build by task and model information.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.LS_funcs as LS_funcs\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_orig = []\n",
    "with open('../mcts-main/dataset/mcts.dev.orig', encoding=\"utf8\") as f:\n",
    "    lines_orig = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_ref = []\n",
    "for dataset in range(0,5):\n",
    "    filename = str('../mcts-main/dataset/mcts.dev.simp.'+str(dataset))\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        lines_ref.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tempu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1113: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lines_sys = []\n",
    "for line in lines_orig:\n",
    "    lines_sys.append(simplify(line,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easse.sari import corpus_sari\n",
    "from easse.bleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sari(orig_sents=lines_orig,\n",
    "    sys_sents=lines_sys,\n",
    "    refs_sents=lines_ref)\n",
    "corpus_bleu(sys_sents=lines_sys,\n",
    "            refs_sents=lines_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
